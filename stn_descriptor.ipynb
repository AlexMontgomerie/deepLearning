{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline_code.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexMontgomerie/deepLearning/blob/master/stn_descriptor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Wy_53YaTgF3_",
        "colab_type": "code",
        "outputId": "c23c4c84-62e0-4c8a-cc39-14646141659f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "#!rm -rf deepLearning\n",
        "!git clone https://github.com/AlexMontgomerie/deepLearning\n",
        "%cd deepLearning\n",
        "!git pull origin master\n",
        "\n",
        "# Taken from\n",
        "# https://stackoverflow.com/questions/48750199/google-colaboratory-misleading-information-about-its-gpu-only-5-ram-available\n",
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# Colab only provides one GPU and it is not always guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'deepLearning'...\n",
            "remote: Enumerating objects: 127, done.\u001b[K\n",
            "remote: Counting objects: 100% (127/127), done.\u001b[K\n",
            "remote: Compressing objects: 100% (105/105), done.\u001b[K\n",
            "remote: Total 372 (delta 64), reused 51 (delta 21), pack-reused 245\u001b[K\n",
            "Receiving objects: 100% (372/372), 152.13 MiB | 20.13 MiB/s, done.\n",
            "Resolving deltas: 100% (147/147), done.\n",
            "Checking out files: 100% (107/107), done.\n",
            "/content/deepLearning\n",
            "From https://github.com/AlexMontgomerie/deepLearning\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n",
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python2.7/dist-packages (0.5.1)\n",
            "('RAM Free: 12.9 GB', ' | Proc size: 152.9 MB')\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zLh6FesVgF4F",
        "colab_type": "code",
        "outputId": "9326f9c6-fb74-438d-93eb-7224692bf21e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "cell_type": "code",
      "source": [
        "from common import *\n",
        "!chmod +x setup.sh\n",
        "!./setup.sh"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-13 10:41:40--  https://imperialcollegelondon.box.com/shared/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Resolving imperialcollegelondon.box.com (imperialcollegelondon.box.com)... 107.152.27.197\n",
            "Connecting to imperialcollegelondon.box.com (imperialcollegelondon.box.com)|107.152.27.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip [following]\n",
            "--2019-03-13 10:41:40--  https://imperialcollegelondon.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Reusing existing connection to imperialcollegelondon.box.com:443.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://imperialcollegelondon.app.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip [following]\n",
            "--2019-03-13 10:41:41--  https://imperialcollegelondon.app.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Resolving imperialcollegelondon.app.box.com (imperialcollegelondon.app.box.com)... 107.152.24.199, 107.152.25.199\n",
            "Connecting to imperialcollegelondon.app.box.com (imperialcollegelondon.app.box.com)|107.152.24.199|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://public.boxcloud.com/d/1/b1!CXcSSgETllC-e_X2h_pTxpiUhYlJw5sczuu8fGzVi_aFnch881tklA36UUOjbsqoFZ2P5rY_MB2gYIKuo04OESz25D3Mi8Py7hFVnYzXloHqnCZRa05fYjHdesscUT6u94VXBWlviY-iktDebQK7XVvDRKnBQ0yHSytqOCw1DUh7XoaNNDRf90oz_JgebM5W6FdeqxBmWikstFKlVje57WfVLWHBSdSXWreYLmGTKbFFJCjxKk0mdtuhh5GFCR8kLJJKcVXZmeBZ7uGvx-TXDOYI3I-q_hJqtqfRhx0bBDtvpVyTqKciDLkyuQgXI294IA6j_lvb8bQwNUN7OBd52_eGIV18mgvSZ4tR_kuJctoxJ7qVnPdvbtNOvk51WZV89RPuWQ_IPD57KpyJsZll363A7xq3De7pMtETug-cdHG2ALWVlq4FWtTF5e3JtNeZWxGa09ub2XI9ovSLw6jB2ke343cACN7rI6pLtsWEjuhYsVFkHHN4FclBzUlizJswi3glKaivZQk1FeL9KNm-qNxXuanlA1ZrHCwHVPYIa4hx2UWaMn76Tn8pnmS0MrvVeLLuDztz-VsrakLo4wnIcMEeENuc7ekflrngqOMCUgORqN40lnlWZgXJbUYlH8DOTTlW-bCu1VLEmZ7OSnbDCmlY7bShnT9G2inhqjjED4ikaGDyomhGZL1MxvqzvcXyOT90Do8XuQqg8awV3LJgMKF98slYYn50zw6MTt36Q-gIJqUxB2kjEtZccJqNqukQlX5K9FkDPAL2YElyQDda_UqF6IPv3hiF95n7FNsOjpn-5tUkfmRGz2y1ukaQQ7HPd4hLioh2bAlyb-dsfBPo2rY2iURwCTVdWtt-gij0mYrrLHUvuK7T9h_te6VZvGhinnZGiZ-lof-wRXQIZ24gLjFk2mN9kjG60pF3Ds8-RcstBI5om7t4JgjUGzvYPtQ95UR2bb9XaKIlvDRaHEyzfEcRvwoHLixFbAVgk0mP77hVve9c5av72vM2tzsYdsd5uZCJ35Qu8PUx2-3Rox5OUTusxXGYe3VrdI6FmRMo3UL6YqskJZy3W5DLnqQDPbNCzWJReoQsoaRYarn2j08q6P_lYUC_icpG06tcTnMiHTuw6tHBna3xCUAlQQyJvRa2YMw5zgRDTNConea6F3iQ8XHbDA2poVNDmGs6_1Ldv5Yv9UH9Oo49JZTLRSOIFhcmWEEemzKkD0RZo3w4Vm6DVg3uBAONYYVR4Yns93zAZJbhI-IhENZxyMoJCO6A-RQXndyoI6yss3SGj7p1UWldY2lpHZOkLULd25iGjbKtubKfd6xA4eQkT3mYDAg6LKfxe7sjrpS8Y9N29NSiKW9Qp1QqbHx9wq6JIX4Mszxj6BDdz4-G7PmL14Qid-0IetN1H_kLwvX2wocPlRYZWn-76sOOD-y1l2nOHLf67EO0lpw9sb1HcWfU9gzbVaKrBjkGTRB7uiCqr8h4Q5j0g9FiqomPT65Pt09F0EzPKw../download [following]\n",
            "--2019-03-13 10:41:41--  https://public.boxcloud.com/d/1/b1!CXcSSgETllC-e_X2h_pTxpiUhYlJw5sczuu8fGzVi_aFnch881tklA36UUOjbsqoFZ2P5rY_MB2gYIKuo04OESz25D3Mi8Py7hFVnYzXloHqnCZRa05fYjHdesscUT6u94VXBWlviY-iktDebQK7XVvDRKnBQ0yHSytqOCw1DUh7XoaNNDRf90oz_JgebM5W6FdeqxBmWikstFKlVje57WfVLWHBSdSXWreYLmGTKbFFJCjxKk0mdtuhh5GFCR8kLJJKcVXZmeBZ7uGvx-TXDOYI3I-q_hJqtqfRhx0bBDtvpVyTqKciDLkyuQgXI294IA6j_lvb8bQwNUN7OBd52_eGIV18mgvSZ4tR_kuJctoxJ7qVnPdvbtNOvk51WZV89RPuWQ_IPD57KpyJsZll363A7xq3De7pMtETug-cdHG2ALWVlq4FWtTF5e3JtNeZWxGa09ub2XI9ovSLw6jB2ke343cACN7rI6pLtsWEjuhYsVFkHHN4FclBzUlizJswi3glKaivZQk1FeL9KNm-qNxXuanlA1ZrHCwHVPYIa4hx2UWaMn76Tn8pnmS0MrvVeLLuDztz-VsrakLo4wnIcMEeENuc7ekflrngqOMCUgORqN40lnlWZgXJbUYlH8DOTTlW-bCu1VLEmZ7OSnbDCmlY7bShnT9G2inhqjjED4ikaGDyomhGZL1MxvqzvcXyOT90Do8XuQqg8awV3LJgMKF98slYYn50zw6MTt36Q-gIJqUxB2kjEtZccJqNqukQlX5K9FkDPAL2YElyQDda_UqF6IPv3hiF95n7FNsOjpn-5tUkfmRGz2y1ukaQQ7HPd4hLioh2bAlyb-dsfBPo2rY2iURwCTVdWtt-gij0mYrrLHUvuK7T9h_te6VZvGhinnZGiZ-lof-wRXQIZ24gLjFk2mN9kjG60pF3Ds8-RcstBI5om7t4JgjUGzvYPtQ95UR2bb9XaKIlvDRaHEyzfEcRvwoHLixFbAVgk0mP77hVve9c5av72vM2tzsYdsd5uZCJ35Qu8PUx2-3Rox5OUTusxXGYe3VrdI6FmRMo3UL6YqskJZy3W5DLnqQDPbNCzWJReoQsoaRYarn2j08q6P_lYUC_icpG06tcTnMiHTuw6tHBna3xCUAlQQyJvRa2YMw5zgRDTNConea6F3iQ8XHbDA2poVNDmGs6_1Ldv5Yv9UH9Oo49JZTLRSOIFhcmWEEemzKkD0RZo3w4Vm6DVg3uBAONYYVR4Yns93zAZJbhI-IhENZxyMoJCO6A-RQXndyoI6yss3SGj7p1UWldY2lpHZOkLULd25iGjbKtubKfd6xA4eQkT3mYDAg6LKfxe7sjrpS8Y9N29NSiKW9Qp1QqbHx9wq6JIX4Mszxj6BDdz4-G7PmL14Qid-0IetN1H_kLwvX2wocPlRYZWn-76sOOD-y1l2nOHLf67EO0lpw9sb1HcWfU9gzbVaKrBjkGTRB7uiCqr8h4Q5j0g9FiqomPT65Pt09F0EzPKw../download\n",
            "Resolving public.boxcloud.com (public.boxcloud.com)... 107.152.24.200, 107.152.25.200\n",
            "Connecting to public.boxcloud.com (public.boxcloud.com)|107.152.24.200|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4088106554 (3.8G) [application/zip]\n",
            "Saving to: ‘hpatches_data.zip’\n",
            "\n",
            "hpatches_data.zip   100%[===================>]   3.81G  20.8MB/s    in 3m 8s   \n",
            "\n",
            "2019-03-13 10:44:50 (20.7 MB/s) - ‘hpatches_data.zip’ saved [4088106554/4088106554]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "W6QbkHnbuIUD",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "import keras\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda, Reshape\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Input, UpSampling2D, concatenate\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from read_data import HPatches, DataGeneratorDesc, hpatches_sequence_folder, DenoiseHPatches, STNHPatches, tps\n",
        "from utils import generate_desc_csv, plot_denoise, plot_triplet, plot_stn\n",
        "import matplotlib.pyplot as plt\n",
        "from layers import BilinearInterpolation\n",
        "\n",
        "random.seed(1234)\n",
        "np.random.seed(1234)\n",
        "tf.set_random_seed(1234)\n",
        "\n",
        "def get_initial_weights(output_size):\n",
        "    b = np.zeros((2, 3), dtype='float32')\n",
        "    b[0, 0] = 1\n",
        "    b[1, 1] = 1\n",
        "    W = np.zeros((output_size, 6), dtype='float32')\n",
        "    weights = [W, b.flatten()]\n",
        "    return weights\n",
        "  \n",
        "def get_stn_model(shape):\n",
        "    init_weights = keras.initializers.he_normal()\n",
        "    inputs = Input(shape)\n",
        "    locnet = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer=init_weights, name='stn_1')(inputs) # 32\n",
        "    locnet = BatchNormalization(axis = -1)(locnet)\n",
        "    locnet = MaxPooling2D(pool_size=(2, 2))(locnet)\n",
        "    \n",
        "    locnet = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer=init_weights, name='stn_2')(locnet) # 32\n",
        "    locnet = BatchNormalization(axis = -1)(locnet)\n",
        "    locnet = MaxPooling2D(pool_size=(2, 2))(locnet)\n",
        "    \n",
        "    locnet = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer=init_weights, name='stn_3')(locnet)  # 64\n",
        "    locnet = BatchNormalization(axis = -1)(locnet)\n",
        "    locnet = MaxPooling2D(pool_size=(2, 2))(locnet)\n",
        "    \n",
        "    locnet = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer=init_weights, name='stn_4')(locnet)  # 128\n",
        "    locnet = BatchNormalization(axis = -1)(locnet)\n",
        "    locnet = MaxPooling2D(pool_size=(2, 2))(locnet)\n",
        "    \n",
        "    locnet = Flatten()(locnet)\n",
        "    locnet = Dense(256, name='stn_5')(locnet)\n",
        "    locnet =  Dropout(0.25)(locnet)\n",
        "    locnet = Activation('softmax')(locnet)\n",
        "    weights = get_initial_weights(256)\n",
        "    locnet = Dense(6, weights=weights, name='stn_6')(locnet)\n",
        "    stn    = BilinearInterpolation(shape[:-1])([inputs, locnet])\n",
        "    #stn = BatchNormalization(axis = -1)(stn)\n",
        "\n",
        "    return Model(inputs=inputs, outputs=stn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ciK2bzUiMqZj",
        "colab_type": "code",
        "outputId": "05c1ce4e-8fd2-4ed9-958a-6e289e6bacad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "%cd /content/deepLearning\n",
        "!git pull origin master"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/deepLearning\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n",
            "From https://github.com/AlexMontgomerie/deepLearning\n",
            " * branch            master     -> FETCH_HEAD\n",
            "   c2c4011..0caff34  master     -> origin/master\n",
            "Updating c2c4011..0caff34\n",
            "Fast-forward\n",
            " utils.py | 42 \u001b[32m+++++++++++++++++++++++++++++++++++\u001b[m\u001b[31m-------\u001b[m\n",
            " 1 file changed, 35 insertions(+), 7 deletions(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7OHNwH_XgF4T",
        "colab_type": "code",
        "outputId": "528d350f-4bf6-4ded-b9ab-a5f8d218f7cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2023
        }
      },
      "cell_type": "code",
      "source": [
        "from get_data import get_data\n",
        "from read_data import STNHPatches\n",
        "\n",
        "seqs_train, seqs_test = get_data()\n",
        "\n",
        "denoise_generator     = STNHPatches(seqs_train, batch_size=500)\n",
        "denoise_generator_val = STNHPatches(seqs_test, batch_size=500)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|▏         | 1/76 [00:00<00:15,  4.80it/s]\u001b[A\n",
            "  3%|▎         | 2/76 [00:00<00:20,  3.57it/s]\u001b[A\n",
            "  4%|▍         | 3/76 [00:01<00:24,  3.04it/s]\u001b[A\n",
            "  5%|▌         | 4/76 [00:01<00:28,  2.49it/s]\u001b[A\n",
            "  7%|▋         | 5/76 [00:02<00:30,  2.33it/s]\u001b[A\n",
            "  8%|▊         | 6/76 [00:02<00:25,  2.75it/s]\u001b[A\n",
            "  9%|▉         | 7/76 [00:02<00:28,  2.46it/s]\u001b[A\n",
            " 11%|█         | 8/76 [00:03<00:24,  2.75it/s]\u001b[A\n",
            " 12%|█▏        | 9/76 [00:03<00:21,  3.14it/s]\u001b[A\n",
            " 13%|█▎        | 10/76 [00:03<00:17,  3.69it/s]\u001b[A\n",
            " 14%|█▍        | 11/76 [00:03<00:15,  4.16it/s]\u001b[A\n",
            " 16%|█▌        | 12/76 [00:03<00:16,  3.84it/s]\u001b[A\n",
            " 17%|█▋        | 13/76 [00:04<00:16,  3.86it/s]\u001b[A\n",
            " 18%|█▊        | 14/76 [00:04<00:15,  4.07it/s]\u001b[A\n",
            " 20%|█▉        | 15/76 [00:04<00:15,  4.00it/s]\u001b[A\n",
            " 22%|██▏       | 17/76 [00:05<00:16,  3.66it/s]\u001b[A\n",
            " 24%|██▎       | 18/76 [00:05<00:15,  3.69it/s]\u001b[A\n",
            " 25%|██▌       | 19/76 [00:06<00:20,  2.82it/s]\u001b[A\n",
            " 26%|██▋       | 20/76 [00:06<00:19,  2.93it/s]\u001b[A\n",
            " 28%|██▊       | 21/76 [00:06<00:15,  3.54it/s]\u001b[A\n",
            " 29%|██▉       | 22/76 [00:06<00:14,  3.71it/s]\u001b[A\n",
            " 30%|███       | 23/76 [00:07<00:12,  4.10it/s]\u001b[A\n",
            " 32%|███▏      | 24/76 [00:07<00:14,  3.59it/s]\u001b[A\n",
            " 33%|███▎      | 25/76 [00:07<00:16,  3.10it/s]\u001b[A\n",
            " 34%|███▍      | 26/76 [00:08<00:13,  3.58it/s]\u001b[A\n",
            " 36%|███▌      | 27/76 [00:08<00:13,  3.64it/s]\u001b[A\n",
            " 37%|███▋      | 28/76 [00:08<00:17,  2.69it/s]\u001b[A\n",
            " 38%|███▊      | 29/76 [00:09<00:15,  2.94it/s]\u001b[A\n",
            " 39%|███▉      | 30/76 [00:09<00:18,  2.45it/s]\u001b[A\n",
            " 41%|████      | 31/76 [00:10<00:20,  2.19it/s]\u001b[A\n",
            " 42%|████▏     | 32/76 [00:10<00:16,  2.72it/s]\u001b[A\n",
            " 43%|████▎     | 33/76 [00:11<00:18,  2.35it/s]\u001b[A\n",
            " 45%|████▍     | 34/76 [00:11<00:16,  2.53it/s]\u001b[A\n",
            " 46%|████▌     | 35/76 [00:11<00:17,  2.39it/s]\u001b[A\n",
            " 47%|████▋     | 36/76 [00:12<00:15,  2.57it/s]\u001b[A\n",
            " 49%|████▊     | 37/76 [00:12<00:15,  2.48it/s]\u001b[A\n",
            " 50%|█████     | 38/76 [00:13<00:17,  2.21it/s]\u001b[A\n",
            " 51%|█████▏    | 39/76 [00:13<00:14,  2.59it/s]\u001b[A\n",
            " 53%|█████▎    | 40/76 [00:13<00:11,  3.16it/s]\u001b[A\n",
            " 54%|█████▍    | 41/76 [00:14<00:13,  2.55it/s]\u001b[A\n",
            " 55%|█████▌    | 42/76 [00:14<00:15,  2.22it/s]\u001b[A\n",
            " 57%|█████▋    | 43/76 [00:15<00:16,  2.04it/s]\u001b[A\n",
            " 58%|█████▊    | 44/76 [00:15<00:16,  1.94it/s]\u001b[A\n",
            " 59%|█████▉    | 45/76 [00:16<00:15,  1.98it/s]\u001b[A\n",
            " 61%|██████    | 46/76 [00:16<00:16,  1.86it/s]\u001b[A\n",
            " 62%|██████▏   | 47/76 [00:17<00:13,  2.14it/s]\u001b[A\n",
            " 63%|██████▎   | 48/76 [00:17<00:10,  2.65it/s]\u001b[A\n",
            " 64%|██████▍   | 49/76 [00:17<00:08,  3.03it/s]\u001b[A\n",
            " 66%|██████▌   | 50/76 [00:17<00:08,  2.98it/s]\u001b[A\n",
            " 67%|██████▋   | 51/76 [00:18<00:09,  2.71it/s]\u001b[A\n",
            " 68%|██████▊   | 52/76 [00:18<00:10,  2.33it/s]\u001b[A\n",
            " 70%|██████▉   | 53/76 [00:19<00:08,  2.60it/s]\u001b[A\n",
            " 71%|███████   | 54/76 [00:19<00:07,  2.88it/s]\u001b[A\n",
            " 72%|███████▏  | 55/76 [00:19<00:07,  2.77it/s]\u001b[A\n",
            " 74%|███████▎  | 56/76 [00:20<00:08,  2.36it/s]\u001b[A\n",
            " 75%|███████▌  | 57/76 [00:20<00:06,  2.84it/s]\u001b[A\n",
            " 76%|███████▋  | 58/76 [00:21<00:06,  2.78it/s]\u001b[A\n",
            " 78%|███████▊  | 59/76 [00:21<00:07,  2.38it/s]\u001b[A\n",
            " 79%|███████▉  | 60/76 [00:21<00:05,  2.93it/s]\u001b[A\n",
            " 80%|████████  | 61/76 [00:22<00:05,  2.84it/s]\u001b[A\n",
            " 82%|████████▏ | 62/76 [00:22<00:04,  2.90it/s]\u001b[A\n",
            " 83%|████████▎ | 63/76 [00:23<00:05,  2.43it/s]\u001b[A\n",
            " 84%|████████▍ | 64/76 [00:23<00:05,  2.16it/s]\u001b[A\n",
            " 86%|████████▌ | 65/76 [00:24<00:05,  2.01it/s]\u001b[A\n",
            " 87%|████████▋ | 66/76 [00:24<00:04,  2.12it/s]\u001b[A\n",
            " 88%|████████▊ | 67/76 [00:25<00:04,  2.01it/s]\u001b[A\n",
            " 89%|████████▉ | 68/76 [00:25<00:03,  2.42it/s]\u001b[A\n",
            " 91%|█████████ | 69/76 [00:25<00:03,  2.33it/s]\u001b[A\n",
            " 92%|█████████▏| 70/76 [00:26<00:02,  2.75it/s]\u001b[A\n",
            " 93%|█████████▎| 71/76 [00:26<00:01,  3.08it/s]\u001b[A\n",
            " 95%|█████████▍| 72/76 [00:26<00:01,  2.54it/s]\u001b[A\n",
            " 96%|█████████▌| 73/76 [00:27<00:00,  3.01it/s]\u001b[A\n",
            " 97%|█████████▋| 74/76 [00:27<00:00,  2.47it/s]\u001b[A\n",
            " 99%|█████████▊| 75/76 [00:27<00:00,  2.98it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:28<00:00,  2.55it/s]\u001b[A\n",
            "\u001b[A\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|▎         | 1/40 [00:00<00:17,  2.27it/s]\u001b[A\n",
            "  5%|▌         | 2/40 [00:00<00:15,  2.48it/s]\u001b[A\n",
            "  8%|▊         | 3/40 [00:01<00:15,  2.35it/s]\u001b[A\n",
            " 10%|█         | 4/40 [00:01<00:16,  2.16it/s]\u001b[A\n",
            " 12%|█▎        | 5/40 [00:02<00:16,  2.12it/s]\u001b[A\n",
            " 15%|█▌        | 6/40 [00:02<00:17,  2.00it/s]\u001b[A\n",
            " 18%|█▊        | 7/40 [00:03<00:16,  1.95it/s]\u001b[A\n",
            " 20%|██        | 8/40 [00:03<00:15,  2.01it/s]\u001b[A\n",
            " 22%|██▎       | 9/40 [00:03<00:11,  2.63it/s]\u001b[A\n",
            " 25%|██▌       | 10/40 [00:04<00:13,  2.21it/s]\u001b[A\n",
            " 28%|██▊       | 11/40 [00:05<00:13,  2.15it/s]\u001b[A\n",
            " 30%|███       | 12/40 [00:05<00:13,  2.00it/s]\u001b[A\n",
            " 32%|███▎      | 13/40 [00:05<00:10,  2.58it/s]\u001b[A\n",
            " 35%|███▌      | 14/40 [00:06<00:11,  2.30it/s]\u001b[A\n",
            " 38%|███▊      | 15/40 [00:06<00:12,  2.08it/s]\u001b[A\n",
            " 40%|████      | 16/40 [00:07<00:11,  2.01it/s]\u001b[A\n",
            " 42%|████▎     | 17/40 [00:08<00:12,  1.91it/s]\u001b[A\n",
            " 45%|████▌     | 18/40 [00:08<00:12,  1.81it/s]\u001b[A\n",
            " 48%|████▊     | 19/40 [00:08<00:10,  2.08it/s]\u001b[A\n",
            " 50%|█████     | 20/40 [00:09<00:08,  2.34it/s]\u001b[A\n",
            " 52%|█████▎    | 21/40 [00:09<00:09,  2.10it/s]\u001b[A\n",
            " 55%|█████▌    | 22/40 [00:10<00:08,  2.05it/s]\u001b[A\n",
            " 57%|█████▊    | 23/40 [00:10<00:08,  1.93it/s]\u001b[A\n",
            " 60%|██████    | 24/40 [00:11<00:07,  2.21it/s]\u001b[A\n",
            " 62%|██████▎   | 25/40 [00:11<00:07,  2.07it/s]\u001b[A\n",
            " 65%|██████▌   | 26/40 [00:11<00:05,  2.62it/s]\u001b[A\n",
            " 68%|██████▊   | 27/40 [00:12<00:04,  2.95it/s]\u001b[A\n",
            " 70%|███████   | 28/40 [00:12<00:03,  3.29it/s]\u001b[A\n",
            " 72%|███████▎  | 29/40 [00:12<00:02,  3.72it/s]\u001b[A\n",
            " 75%|███████▌  | 30/40 [00:13<00:03,  2.75it/s]\u001b[A\n",
            " 78%|███████▊  | 31/40 [00:13<00:03,  2.55it/s]\u001b[A\n",
            " 80%|████████  | 32/40 [00:13<00:02,  3.15it/s]\u001b[A\n",
            " 82%|████████▎ | 33/40 [00:14<00:02,  2.50it/s]\u001b[A\n",
            " 85%|████████▌ | 34/40 [00:14<00:02,  2.22it/s]\u001b[A\n",
            " 90%|█████████ | 36/40 [00:15<00:01,  2.42it/s]\u001b[A\n",
            " 92%|█████████▎| 37/40 [00:15<00:01,  2.83it/s]\u001b[A\n",
            " 95%|█████████▌| 38/40 [00:16<00:00,  2.39it/s]\u001b[A\n",
            " 98%|█████████▊| 39/40 [00:16<00:00,  2.29it/s]\u001b[A\n",
            "100%|██████████| 40/40 [00:17<00:00,  2.18it/s]\u001b[A\n",
            "\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "yTLGGPLvHIAP",
        "colab_type": "code",
        "outputId": "78df81ed-aa4f-4e32-a690-8d96958fa254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1833
        }
      },
      "cell_type": "code",
      "source": [
        "# get model\n",
        "shape = (32, 32, 1)\n",
        "stn_model = get_stn_model(shape)\n",
        "\n",
        "# optimiser\n",
        "opt  = opt = keras.optimizers.nadam()\n",
        "\n",
        "# loss\n",
        "loss = 'mean_absolute_error'\n",
        "\n",
        "# train network\n",
        "def ssim_loss(a,p):\n",
        "  return 1 - tf.image.ssim(a, p, max_val=1.0)\n",
        "\n",
        "# callbacks\n",
        "callbacks = [\n",
        "    #keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 5, verbose = 3, mode= 'auto'),\n",
        "    keras.callbacks.ModelCheckpoint('data/stn_model.weights.{epoch:02d}-{val_loss:.2f}.hdf5', verbose=1, save_best_only=True)\n",
        "]\n",
        "\n",
        "stn_model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
        "stn_history = stn_model.fit_generator(generator=denoise_generator, epochs=25, callbacks=callbacks,\n",
        "                                              verbose=1, validation_data=denoise_generator_val)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1169/1169 [==============================] - 118s 101ms/step - loss: 26.6732 - acc: 0.1514 - val_loss: 23.2482 - val_acc: 0.1625\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 23.24818, saving model to data/stn_model.weights.01-23.25.hdf5\n",
            "Epoch 2/25\n",
            "1169/1169 [==============================] - 116s 99ms/step - loss: 26.6492 - acc: 0.1559 - val_loss: 26.0048 - val_acc: 0.1477\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 23.24818\n",
            "Epoch 3/25\n",
            "1169/1169 [==============================] - 116s 99ms/step - loss: 26.7086 - acc: 0.1564 - val_loss: 23.6767 - val_acc: 0.1651\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 23.24818\n",
            "Epoch 4/25\n",
            "1169/1169 [==============================] - 113s 97ms/step - loss: 26.8017 - acc: 0.1594 - val_loss: 25.1562 - val_acc: 0.1739\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 23.24818\n",
            "Epoch 5/25\n",
            "1169/1169 [==============================] - 114s 97ms/step - loss: 26.8632 - acc: 0.1605 - val_loss: 26.2761 - val_acc: 0.1093\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 23.24818\n",
            "Epoch 6/25\n",
            "1169/1169 [==============================] - 115s 98ms/step - loss: 26.8796 - acc: 0.1609 - val_loss: 23.7750 - val_acc: 0.1661\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 23.24818\n",
            "Epoch 7/25\n",
            "1169/1169 [==============================] - 114s 97ms/step - loss: 26.8998 - acc: 0.1618 - val_loss: 24.7510 - val_acc: 0.1337\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 23.24818\n",
            "Epoch 8/25\n",
            "1169/1169 [==============================] - 113s 96ms/step - loss: 26.9373 - acc: 0.1580 - val_loss: 23.5640 - val_acc: 0.1707\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 23.24818\n",
            "Epoch 9/25\n",
            "1169/1169 [==============================] - 113s 96ms/step - loss: 27.1285 - acc: 0.1655 - val_loss: 26.3210 - val_acc: 0.1485\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 23.24818\n",
            "Epoch 10/25\n",
            "1169/1169 [==============================] - 116s 99ms/step - loss: 27.2167 - acc: 0.1674 - val_loss: 24.7371 - val_acc: 0.1727\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 23.24818\n",
            "Epoch 11/25\n",
            "1169/1169 [==============================] - 114s 97ms/step - loss: 27.2779 - acc: 0.1687 - val_loss: 24.3204 - val_acc: 0.1613\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 23.24818\n",
            "Epoch 12/25\n",
            " 113/1169 [=>............................] - ETA: 1:25 - loss: 27.3629 - acc: 0.1681"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-214d0814590f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mstn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m stn_history = stn_model.fit_generator(generator=denoise_generator, epochs=25, callbacks=callbacks,\n\u001b[0;32m---> 22\u001b[0;31m                                               verbose=1, validation_data=denoise_generator_val)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training_generator.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "aikyKw4-tRJJ",
        "colab_type": "code",
        "outputId": "a303a182-0fc6-44d3-e266-5c521300e2ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "cell_type": "code",
      "source": [
        "from utils import plot_stn\n",
        "\n",
        "plot_stn(stn_model)\n",
        "plt.plot(stn_history.history['loss'])\n",
        "plt.plot(stn_history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.95it/s]\u001b[A\n",
            "\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdUAAACmCAYAAACMeBUsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxCRoVAkhhBCT+H9I13VC/Tz4cwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-b310d1198353>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplot_stn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstn_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstn_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstn_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'stn_history' is not defined"
          ]
        }
      ]
    }
  ]
}