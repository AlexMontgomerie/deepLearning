{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexMontgomerie/deepLearning/blob/master/denoise_additive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "hjTIqmNec40a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "3f64dc04-8fdb-4c16-c252-7c49ab7c631e"
      },
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "#!rm -rf deepLearning\n",
        "!git clone https://github.com/AlexMontgomerie/deepLearning\n",
        "%cd deepLearning\n",
        "!git pull origin master\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "# Taken from\n",
        "# https://stackoverflow.com/questions/48750199/google-colaboratory-misleading-information-about-its-gpu-only-5-ram-available\n",
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# Colab only provides one GPU and it is not always guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "fatal: destination path 'deepLearning' already exists and is not an empty directory.\n",
            "/content/deepLearning\n",
            "From https://github.com/AlexMontgomerie/deepLearning\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n",
            "Collecting gputil\n",
            "  Using cached https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python2.7/dist-packages (0.5.1)\n",
            "Requirement already satisfied: gputil in /usr/local/lib/python2.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python2.7/dist-packages (0.5.1)\n",
            "('RAM Free: 10.7 GB', ' | Proc size: 150.4 MB')\n",
            "GPU RAM Free: 4015MB | Used: 7426MB | Util  65% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lPQ7XCWvdZ6H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ffe632c1-80c3-494a-e9ed-99bc0284331b"
      },
      "cell_type": "code",
      "source": [
        "from common import *\n",
        "!./setup.sh"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "-BV5WKqNdfgo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import sys\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "import keras\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda, Reshape\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Input, UpSampling2D, concatenate, Subtract\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from read_data import HPatches, DataGeneratorDesc, hpatches_sequence_folder, DenoiseHPatches, tps\n",
        "from utils import generate_desc_csv, plot_denoise, plot_triplet\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_denoise_model_additive(shape):\n",
        "\n",
        "  inputs = Input(shape)\n",
        "  \n",
        "  # convolution layers\n",
        "  conv3  = Conv2D(8, 3 , activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "  conv5  = Conv2D(8, 5 , activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "  conv7  = Conv2D(8, 7 , activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "  conv11 = Conv2D(8, 11, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "  \n",
        "  # network\n",
        "  net = Subtract()([inputs, conv3])\n",
        "  net = BatchNormalization()(net)\n",
        "  net = Subtract()([inputs, conv5])\n",
        "  net = BatchNormalization()(net)\n",
        "  net = Subtract()([inputs, conv7])\n",
        "  net = BatchNormalization()(net)\n",
        "  net = Subtract()([inputs, conv11])\n",
        "  net = BatchNormalization()(net)  \n",
        "\n",
        "  return Model(inputs = inputs, outputs = net)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}