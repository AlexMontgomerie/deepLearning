{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexMontgomerie/deepLearning/blob/master/descriptor_improved.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "SLrNzUl5vaLr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "c7a1128e-9ca1-445c-ce4e-510f94a56350"
      },
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "#!rm -rf deepLearning\n",
        "!git clone https://github.com/AlexMontgomerie/deepLearning\n",
        "%cd deepLearning\n",
        "!git pull origin master\n",
        "\n",
        "# Taken from\n",
        "# https://stackoverflow.com/questions/48750199/google-colaboratory-misleading-information-about-its-gpu-only-5-ram-available\n",
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# Colab only provides one GPU and it is not always guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'deepLearning'...\n",
            "remote: Enumerating objects: 76, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (62/62), done.\u001b[K\n",
            "remote: Total 321 (delta 40), reused 33 (delta 13), pack-reused 245\u001b[K\n",
            "Receiving objects: 100% (321/321), 150.46 MiB | 18.46 MiB/s, done.\n",
            "Resolving deltas: 100% (123/123), done.\n",
            "Checking out files: 100% (101/101), done.\n",
            "/content/deepLearning\n",
            "From https://github.com/AlexMontgomerie/deepLearning\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n",
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python2.7/dist-packages (0.5.1)\n",
            "('RAM Free: 12.9 GB', ' | Proc size: 152.6 MB')\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wXwp037-vxPf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "e0e0e7ed-b5d9-4792-fab7-c1486b01f015"
      },
      "cell_type": "code",
      "source": [
        "from common import *\n",
        "!./setup.sh"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--2019-03-08 14:40:34--  https://imperialcollegelondon.box.com/shared/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Resolving imperialcollegelondon.box.com (imperialcollegelondon.box.com)... 107.152.26.197\n",
            "Connecting to imperialcollegelondon.box.com (imperialcollegelondon.box.com)|107.152.26.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip [following]\n",
            "--2019-03-08 14:40:34--  https://imperialcollegelondon.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Reusing existing connection to imperialcollegelondon.box.com:443.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://imperialcollegelondon.app.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip [following]\n",
            "--2019-03-08 14:40:34--  https://imperialcollegelondon.app.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Resolving imperialcollegelondon.app.box.com (imperialcollegelondon.app.box.com)... 107.152.26.199\n",
            "Connecting to imperialcollegelondon.app.box.com (imperialcollegelondon.app.box.com)|107.152.26.199|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://public.boxcloud.com/d/1/b1!KgFfoA6QRflQgepVOtYChmjfGyiUxEZO53tLsAvFBdcteCAZyD_64knJHhAnxDR1tth6ZtjQnNoM0F5TEvradk9rV6q3etGs6Tx4srANpoJfWCr1Sa-JICjHk7dRJTvvHfRmmWRIrdotBckAtTPMR9wLiZaG08pu501-xFQ8fmaNRA_d1s6h62CCpX7ZeiVDWCgW4qo28pKkaHyCzKRvHoOhnBhKzmGdIpojXX7sMRW9Fj8-5iru53qWP0FmV4Qp-pcp2gXsZxjDXSc1eeJKaJGmH0tt-NK9xEDblIVoU67oNdH5dWwjfKzJfffOYrf7o0GqLbExziduJkvqVMApVPMNqb3kbjRamB8ZKp2CwlxJ72tGjPJU54H92SEE-uFAVwHrni5Ok1rRt7VnHU0B5afp-WnNGAleCvWhykCroNMlmgDUMhnke1YT3AEkiPyMsyOQICQ_uT9wIIkWJR2GkVx8t8phTgmDpG0L0C5pRUhjUv6qd5pRQzpoTjVlAzRtU55WjT4gmXFEu_4AZRJuxKp2r0GZ5v-rJhqcYOXhcrw1DV4tHHDZnRZcv2WgJQ_xhUGyg6ddnuAdxRuhdQ925XNuzqwMoLybnzY-X8iWDGXhY2texy84YDbnrp-1ZP8C8sT1GiBdkUXTHleeV4zX_GOyIwhrUKX__Y0KCB4uxwi9PWdC30wtRDKtZAYMx_fZ5OLNmMH7fC6XqQ2YzL2fGQPDwIkMS5Rxf8newqI_Jgf1WZ-xyA25LOVBqyftJZwhR5FZGBvPK_qMBvYYuMnaR0KRwXSy-nb5HTM3iOKJ0F8bQwZM5F4a8vq26GxXXubYi2RCW_zHU96x9jQhut0poKJfnbNSPVazZOWc8I2spXFMF-vBhjkjuJKR66TI3Zn7xr3YjCt0Ez9aPi2XTaWcg6B679ATdUkofCYS_Psb81DzTGrrYJS_b4F6Zl4tA-GYQcw4BSUYFHMlEOwDPwgxRnj4bTMmudPJm1UCHgO4dXn1YO0IWa9-Cr66iQvKAQkXBddPJsJmpEsTDsIeimJQEJuzxxmNBhkpMVPuFOvGlDr3k4wG8v-hZ2Wf3ep-qyhLypK7ipmoLpguwPHX0t2loUNy-ZfyAvDo0TM-yMRqroOu7Ir5DrRXvIA57fIeLhH_Rtccq8NJXNTWoxcmgWCB3wtaNWXDxFJ3C0E3VUFAojW_ZkPihB456m5XZufn71AjHSbPgwVcJDA6zcEyTDFCeM80Q2eOKO2JxDD9fihnXu_DE7IzMnjFnA08DevxE8h6zhyRYyZZDj1k_1Q2jDbx8vtu3zPB6LP8rDcXqmxEvKmwCEGCuRLkeaSY3NesfaLyEzeNRmfurM4gjvatSPCseYAExzleyy0qF_GOx47IA2f7r-fkTY6DbQtjy8QKsw7djBNXT8oPzFQxH4sfrAB7fZ5i6CmVu8KTXfkmvcPuL92QnoOQ6ReBp6z7Ea7i7YqpK8i6JlH84Vs9zl-x9CsA9oSqs3m6gIIV/download [following]\n",
            "--2019-03-08 14:40:35--  https://public.boxcloud.com/d/1/b1!KgFfoA6QRflQgepVOtYChmjfGyiUxEZO53tLsAvFBdcteCAZyD_64knJHhAnxDR1tth6ZtjQnNoM0F5TEvradk9rV6q3etGs6Tx4srANpoJfWCr1Sa-JICjHk7dRJTvvHfRmmWRIrdotBckAtTPMR9wLiZaG08pu501-xFQ8fmaNRA_d1s6h62CCpX7ZeiVDWCgW4qo28pKkaHyCzKRvHoOhnBhKzmGdIpojXX7sMRW9Fj8-5iru53qWP0FmV4Qp-pcp2gXsZxjDXSc1eeJKaJGmH0tt-NK9xEDblIVoU67oNdH5dWwjfKzJfffOYrf7o0GqLbExziduJkvqVMApVPMNqb3kbjRamB8ZKp2CwlxJ72tGjPJU54H92SEE-uFAVwHrni5Ok1rRt7VnHU0B5afp-WnNGAleCvWhykCroNMlmgDUMhnke1YT3AEkiPyMsyOQICQ_uT9wIIkWJR2GkVx8t8phTgmDpG0L0C5pRUhjUv6qd5pRQzpoTjVlAzRtU55WjT4gmXFEu_4AZRJuxKp2r0GZ5v-rJhqcYOXhcrw1DV4tHHDZnRZcv2WgJQ_xhUGyg6ddnuAdxRuhdQ925XNuzqwMoLybnzY-X8iWDGXhY2texy84YDbnrp-1ZP8C8sT1GiBdkUXTHleeV4zX_GOyIwhrUKX__Y0KCB4uxwi9PWdC30wtRDKtZAYMx_fZ5OLNmMH7fC6XqQ2YzL2fGQPDwIkMS5Rxf8newqI_Jgf1WZ-xyA25LOVBqyftJZwhR5FZGBvPK_qMBvYYuMnaR0KRwXSy-nb5HTM3iOKJ0F8bQwZM5F4a8vq26GxXXubYi2RCW_zHU96x9jQhut0poKJfnbNSPVazZOWc8I2spXFMF-vBhjkjuJKR66TI3Zn7xr3YjCt0Ez9aPi2XTaWcg6B679ATdUkofCYS_Psb81DzTGrrYJS_b4F6Zl4tA-GYQcw4BSUYFHMlEOwDPwgxRnj4bTMmudPJm1UCHgO4dXn1YO0IWa9-Cr66iQvKAQkXBddPJsJmpEsTDsIeimJQEJuzxxmNBhkpMVPuFOvGlDr3k4wG8v-hZ2Wf3ep-qyhLypK7ipmoLpguwPHX0t2loUNy-ZfyAvDo0TM-yMRqroOu7Ir5DrRXvIA57fIeLhH_Rtccq8NJXNTWoxcmgWCB3wtaNWXDxFJ3C0E3VUFAojW_ZkPihB456m5XZufn71AjHSbPgwVcJDA6zcEyTDFCeM80Q2eOKO2JxDD9fihnXu_DE7IzMnjFnA08DevxE8h6zhyRYyZZDj1k_1Q2jDbx8vtu3zPB6LP8rDcXqmxEvKmwCEGCuRLkeaSY3NesfaLyEzeNRmfurM4gjvatSPCseYAExzleyy0qF_GOx47IA2f7r-fkTY6DbQtjy8QKsw7djBNXT8oPzFQxH4sfrAB7fZ5i6CmVu8KTXfkmvcPuL92QnoOQ6ReBp6z7Ea7i7YqpK8i6JlH84Vs9zl-x9CsA9oSqs3m6gIIV/download\n",
            "Resolving public.boxcloud.com (public.boxcloud.com)... 107.152.27.200\n",
            "Connecting to public.boxcloud.com (public.boxcloud.com)|107.152.27.200|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4088106554 (3.8G) [application/zip]\n",
            "Saving to: ‘hpatches_data.zip’\n",
            "\n",
            "hpatches_data.zip   100%[===================>]   3.81G  20.9MB/s    in 3m 11s  \n",
            "\n",
            "2019-03-08 14:43:46 (20.4 MB/s) - ‘hpatches_data.zip’ saved [4088106554/4088106554]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gHxMGoeCv0hI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "import keras\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda, Reshape\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Input, UpSampling2D, concatenate\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from read_data import HPatches, DataGeneratorDesc, hpatches_sequence_folder, DenoiseHPatches, STNHPatches, tps\n",
        "from utils import generate_desc_csv, plot_denoise, plot_triplet\n",
        "import matplotlib.pyplot as plt\n",
        "from layers import BilinearInterpolation\n",
        "from keras.layers import Layer, Lambda\n",
        "\n",
        "def run_sobel(image):\n",
        "  return tf.image.sobel_edges(image)[:,:,:,0]\n",
        "      \n",
        "\n",
        "def get_initial_weights(output_size):\n",
        "    b = np.zeros((2, 3), dtype='float32')\n",
        "    b[0, 0] = 1\n",
        "    b[1, 1] = 1\n",
        "    W = np.zeros((output_size, 6), dtype='float32')\n",
        "    weights = [W, b.flatten()]\n",
        "    return weights\n",
        "  \n",
        "def get_descriptor_model(shape,stn_init=None):\n",
        "    \n",
        "    #shape = (32, 32, 1)\n",
        "\n",
        "    init_weights = keras.initializers.he_normal()\n",
        "    # input \n",
        "    inputs = Input(shape)\n",
        "    \n",
        "    # stn network    \n",
        "    locnet = MaxPooling2D(pool_size=(2, 2))(inputs)\n",
        "    locnet = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer=init_weights)(locnet)\n",
        "    locnet = MaxPooling2D(pool_size=(2, 2))(locnet)\n",
        "    locnet = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer=init_weights)(locnet)\n",
        "    locnet = MaxPooling2D(pool_size=(2, 2))(locnet)\n",
        "    locnet = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer=init_weights)(locnet)\n",
        "    locnet = Flatten()(locnet)\n",
        "    locnet = Dense(100)(locnet)\n",
        "    locnet = Activation('sigmoid')(locnet)\n",
        "    weights = get_initial_weights(100)\n",
        "    locnet = Dense(6, weights=weights)(locnet)\n",
        "    stn    = BilinearInterpolation(shape[:-1])([inputs, locnet])\n",
        "    \n",
        "    if stn_init:\n",
        "      stn.set_weights(stn_init.get_weights())\n",
        "      \n",
        "    # sobel\n",
        "    sobel = Lambda(run_sobel)(inputs)\n",
        "    \n",
        "    # features in\n",
        "    #l2net = concatenate([ inputs, stn, sobel[:,:,:,:,0], sobel[:,:,:,:,1] ], axis = -1)\n",
        "    l2net = concatenate([ inputs, stn , sobel ], axis = -1)\n",
        "    #l2net = concatenate([inputs,stn,])#, axis = -1)\n",
        "\n",
        "    # L2 Net    \n",
        "    l2net = Conv2D(32, 3, padding='same', input_shape=shape, use_bias = True, kernel_initializer=init_weights)(l2net)\n",
        "    l2net = BatchNormalization(axis = -1)(l2net)\n",
        "    l2net = Activation('relu')(l2net)\n",
        "    \n",
        "    l2net = Conv2D(32, 3, padding='same', input_shape=shape, use_bias = True, kernel_initializer=init_weights)(l2net)\n",
        "    l2net = BatchNormalization(axis = -1)(l2net)\n",
        "    l2net = Activation('relu')(l2net)\n",
        "    \n",
        "    l2net = Conv2D(64, 3, padding='same', input_shape=shape, strides=2, use_bias = True, kernel_initializer=init_weights)(l2net)\n",
        "    l2net = BatchNormalization(axis = -1)(l2net)\n",
        "    l2net = Activation('relu')(l2net)\n",
        "    \n",
        "    l2net = Conv2D(64, 3, padding='same', input_shape=shape, use_bias = True, kernel_initializer=init_weights)(l2net)\n",
        "    l2net = BatchNormalization(axis = -1)(l2net)\n",
        "    l2net = Activation('relu')(l2net)\n",
        "    \n",
        "    l2net = Conv2D(128, 3, padding='same', input_shape=shape, strides=2, use_bias = True, kernel_initializer=init_weights)(l2net)\n",
        "    l2net = BatchNormalization(axis = -1)(l2net)\n",
        "    l2net = Activation('relu')(l2net)\n",
        "    \n",
        "    l2net = Conv2D(128, 3, padding='same', input_shape=shape, use_bias = True, kernel_initializer=init_weights)(l2net)\n",
        "    l2net = BatchNormalization(axis = -1)(l2net)\n",
        "    l2net = Activation('relu')(l2net)\n",
        "    \n",
        "    l2net = Conv2D(128, 8, padding='valid', input_shape=shape, use_bias = True, kernel_initializer=init_weights)(l2net)\n",
        "\n",
        "    l2net = Reshape((128,))(l2net)\n",
        "  \n",
        "    l2net = Model(inputs = inputs, outputs = l2net)\n",
        "    \n",
        "    descriptor_model = Sequential()\n",
        "    descriptor_model.add(l2net)\n",
        "    \n",
        "    return descriptor_model\n",
        "\n",
        "    \n",
        "  \n",
        "from keras.layers import Lambda\n",
        "shape = (32, 32, 1)\n",
        "xa = Input(shape=shape, name='a')\n",
        "xp = Input(shape=shape, name='p')\n",
        "xn = Input(shape=shape, name='n')\n",
        "descriptor_model = get_descriptor_model(shape)\n",
        "ea = descriptor_model(xa)\n",
        "ep = descriptor_model(xp)\n",
        "en = descriptor_model(xn)\n",
        "\n",
        "  \n",
        "def triplet_loss(x):\n",
        "  \n",
        "  output_dim = 128\n",
        "  a, p, n = x\n",
        "  _alpha = 1.0\n",
        "  positive_distance = K.mean(K.square(a - p), axis=-1)\n",
        "  negative_distance = K.mean(K.square(a - n), axis=-1)\n",
        "  \n",
        "  return K.expand_dims(K.maximum(0.0, positive_distance - negative_distance + _alpha), axis = 1)\n",
        "\n",
        "\n",
        "loss = Lambda(triplet_loss)([ea, ep, en])\n",
        "\n",
        "descriptor_model_trip = Model(inputs=[xa, xp, xn], outputs=loss)\n",
        "sgd = keras.optimizers.SGD(lr=0.1)\n",
        "descriptor_model_trip.compile(loss='mean_absolute_error', optimizer=sgd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kPPIWMMMBH2o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "48199218-bd94-4216-bb2e-0b8823854d52"
      },
      "cell_type": "code",
      "source": [
        "hpatches_dir = './hpatches'\n",
        "splits_path = './splits.json'\n",
        "\n",
        "splits_json = json.load(open(splits_path, 'rb'))\n",
        "split = splits_json['a']\n",
        "\n",
        "train_fnames = split['train']\n",
        "test_fnames = split['test']\n",
        "\n",
        "seqs = glob.glob(hpatches_dir+'/*')\n",
        "seqs = [os.path.abspath(p) for p in seqs]   \n",
        "seqs_train = list(filter(lambda x: x.split('/')[-1] in train_fnames, seqs)) \n",
        "seqs_test = list(filter(lambda x: x.split('/')[-1] in split['test'], seqs))\n",
        "\n",
        "### Descriptor loading and training\n",
        "# Loading images\n",
        "hPatches = HPatches(train_fnames=train_fnames, test_fnames=test_fnames,\n",
        "                    use_clean=True)\n",
        "# Creating training generator\n",
        "training_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=1), num_triplets=100000, batch_size=500)\n",
        "# Creating validation generator\n",
        "val_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=0), num_triplets=10000, batch_size=500)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using clean patches\n",
            "100%|██████████| 116/116 [00:35<00:00,  2.86it/s]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [00:02<00:00, 48840.29it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using clean patches\n",
            "100%|██████████| 116/116 [00:21<00:00,  5.51it/s]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 59767.16it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "5fPR5FR1BRFX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1510
        },
        "outputId": "3257a75b-8b66-40e0-c8c5-ce75336b6b25"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "epochs = 50\n",
        "### As with the denoising model, we use a loop to save for each epoch \n",
        "## #the weights in an external website in case colab stops. \n",
        "### reset, so e.g. calling 5 times fit(epochs=1) behave as fit(epochs=5)\n",
        "\n",
        "### If you have a model saved from a previous training session\n",
        "### Load it in the next line\n",
        "# descriptor_model_trip.set_weights(keras.models.load_model('./descriptor.h5').get_weights())\n",
        "# descriptor_model_trip.optimizer = keras.models.load_model('./descriptor.h5').optimizer\n",
        "\n",
        "# callbacks\n",
        "callbacks = [\n",
        "    #keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 5, verbose = 3, mode= 'auto'),\n",
        "    keras.callbacks.ModelCheckpoint('data/descriptor_model.weights.{epoch:02d}-{val_loss:.2f}.hdf5', verbose=1, save_best_only=True)\n",
        "]\n",
        "\n",
        "descriptor_history = descriptor_model_trip.fit_generator(generator=training_generator, epochs=40, callbacks=callbacks,\n",
        "                                              verbose=1, validation_data=val_generator)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "199/200 [============================>.] - ETA: 0s - loss: 0.0434"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [00:02<00:00, 38333.42it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 104s 522ms/step - loss: 0.0435 - val_loss: 0.0712\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.07120, saving model to data/descriptor_model.weights.01-0.07.hdf5\n",
            "Epoch 2/40\n",
            "  2/200 [..............................] - ETA: 1:45 - loss: 0.0404"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 35901.10it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "199/200 [============================>.] - ETA: 0s - loss: 0.0433"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 79%|███████▉  | 79040/100000 [00:02<00:00, 36360.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 104s 520ms/step - loss: 0.0434 - val_loss: 0.0701\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.07120 to 0.07011, saving model to data/descriptor_model.weights.02-0.07.hdf5\n",
            "Epoch 3/40\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 85553/100000 [00:03<00:01, 8379.91it/s] \n",
            "  0%|          | 0/10000 [00:00<?, ?it/s]\u001b[A\n",
            " 88%|████████▊ | 87631/100000 [00:03<00:01, 8672.54it/s]\n",
            " 15%|█▌        | 1548/10000 [00:00<00:01, 6980.66it/s]\u001b[A\n",
            " 22%|██▏       | 2171/10000 [00:00<00:01, 6736.57it/s]\u001b[A\n",
            " 89%|████████▉ | 89369/100000 [00:03<00:01, 8174.18it/s]\n",
            " 38%|███▊      | 3817/10000 [00:00<00:00, 7445.49it/s]\u001b[A\n",
            " 91%|█████████ | 90802/100000 [00:04<00:01, 7764.33it/s]\n",
            " 53%|█████▎    | 5321/10000 [00:00<00:00, 7509.92it/s]\u001b[A\n",
            " 92%|█████████▏| 92014/100000 [00:04<00:01, 7331.84it/s]\n",
            " 93%|█████████▎| 93057/100000 [00:04<00:00, 6986.89it/s]\n",
            " 94%|█████████▍| 93976/100000 [00:04<00:00, 6538.11it/s]\n",
            " 88%|████████▊ | 8800/10000 [00:01<00:00, 7253.53it/s]\u001b[A\n",
            " 95%|█████████▍| 94790/100000 [00:04<00:00, 6572.35it/s]\n",
            "100%|██████████| 100000/100000 [00:05<00:00, 19045.72it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 28/200 [===>..........................] - ETA: 1:44 - loss: 0.0452"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-01970c9b61b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m descriptor_history = descriptor_model_trip.fit_generator(generator=training_generator, epochs=40, callbacks=callbacks,\n\u001b[0;32m---> 19\u001b[0;31m                                               verbose=1, validation_data=val_generator)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training_generator.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}