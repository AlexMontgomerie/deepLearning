{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "denoise.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexMontgomerie/deepLearning/blob/master/denoise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "dDzgB3PlxNwk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Denoise Network"
      ]
    },
    {
      "metadata": {
        "id": "8NE2E99sxSpo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Google Setup"
      ]
    },
    {
      "metadata": {
        "id": "Q7zEuV1zxUsw",
        "colab_type": "code",
        "outputId": "e4614079-0137-4c9b-f0ae-4e8f0248603b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "cell_type": "code",
      "source": [
        "#%cd /content\n",
        "#!rm -rf deepLearning\n",
        "#!git clone https://github.com/AlexMontgomerie/deepLearning\n",
        "#%cd deepLearning\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "'''\n",
        "import os\n",
        "import pprint\n",
        "import tensorflow as tf\n",
        "\n",
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "  print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "else:\n",
        "  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  print ('TPU address is', tpu_address)\n",
        "\n",
        "  with tf.Session(tpu_address) as session:\n",
        "    devices = session.list_devices()\n",
        "    \n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(devices)\n",
        "'''\n",
        "# Taken from\n",
        "# https://stackoverflow.com/questions/48750199/google-colaboratory-misleading-information-about-its-gpu-only-5-ram-available\n",
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# Colab only provides one GPU and it is not always guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "APrJZ0fsxNwl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ]
    },
    {
      "metadata": {
        "id": "Mrsas8WmxNwm",
        "colab_type": "code",
        "outputId": "43ff450d-bdc5-428f-e0f5-00bd4f64ccbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "cell_type": "code",
      "source": [
        "from common import *\n",
        "!./setup.sh"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-25 19:48:08--  https://imperialcollegelondon.box.com/shared/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Resolving imperialcollegelondon.box.com (imperialcollegelondon.box.com)... 107.152.26.197\n",
            "Connecting to imperialcollegelondon.box.com (imperialcollegelondon.box.com)|107.152.26.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip [following]\n",
            "--2019-02-25 19:48:09--  https://imperialcollegelondon.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Reusing existing connection to imperialcollegelondon.box.com:443.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://imperialcollegelondon.app.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip [following]\n",
            "--2019-02-25 19:48:09--  https://imperialcollegelondon.app.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Resolving imperialcollegelondon.app.box.com (imperialcollegelondon.app.box.com)... 107.152.26.199\n",
            "Connecting to imperialcollegelondon.app.box.com (imperialcollegelondon.app.box.com)|107.152.26.199|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://public.boxcloud.com/d/1/b1!7hNRhZtY_F5cz5W5wy_zfhHec_4QTG6WWnnNaIbW0bF1eoXpL8seHYNcC45FYf4P2HIQ6yrgZxK7BmIQ2DsC0Lab2iX1Hj12a8400wqR1Mr-9GPnySkkvDdnkhJAlyGM7W7dMoTrL94XStGK6E581vMw_0L95V_9qgFO7g3anzMVRZJHiYM7AUk4FfPtJmUQZoGHN372a6VNYNdpAQahvYgMijVjZb0lXXa40TL07Yqc-WcmQKlBaeeSCc9-oJxAlc8SKRDoYmZruQOD81kWRsgs4ypGT3CkxwBdh87NYAGBZSPCNLTvQikxFPTCBx8Vk6Dl_EcbhSZJHGgGrjwA0UL9UH_nTeB4tQnBp3MEfnIIMftjN7M_yoJ-yEExjkbZzfRcGZENpR6KBhsaZue_mXSUa29JUr5YT0N49gvC6lr7rJQsVP8-bdSAF5st9wn2ISd814bOjHr3n98bXvSBdSaYblvsXE3aFc4u9APFT3iei3MtgPgR-FjlxiB4ClL24LczPKrwbJrYAFYDl5siKBIeXn6eKYob9cBKYPoUUTnDt1wrZemgu0ColxEa836ZIsaTyU3rAnSUuSWF_APmEE3HUxrjhZbZjUkQcAsuDx6eYl4vR92WdB9kS66DVZrrgQ3Bpen6xA_6Oc_PkW1WgCJb3Sly0h1_0kjcguIUYiw-sMAIOPnLAnsXnAR1OCkXywZBlFzF9LEAJJ56VLcOVI0khnTfSo8DHk49t19l8HJvw4b6wwmC-wvDeH9HiMscm2a0zlc0Gkofrwxhap5qtLsl68DXMJBS5P6iIy7ffpSV91TKcvouo53dDofxYaIlddU6O0Bhatws7fQJfkD_6j0UVJ5NwlCwzn70Ch5Q13tsebtRtP0xL37Ijwci59KzvnL4nb55Y-yHTEpioBDmmDkyjwKJnn4MOFw9qhf8ZiEaVp-0i29V8NEX8fznFWhF-ihw3wf4X21GYGW9fqa0Qk52yOB0rEqRV6ncIU_nJCQZ2yEMGbNu00kpvRJ7JVkMZPb-rvi_lFUlbqWclBv3j8IzH2nztBDOB0fL1mc000nERJWOgihyAEqVah0lfxOlbJtrVkN45GVRUO0R2e1wjYg7H8tBlfFVyohWYxH8AE-KSNe9AlHt3IrO4fyuELm4kljve1q5qHHpQEpBQJAs072pr-O3FsGOOQwvqbBDFLvYlnB4W5rAGfwqmuL-KVvOGK4QkqzNJrfxmRwuFK4wXmilACUSuHMEiyFjRJniVHE3Ea3-YFYdTlPeuKHWx2r5QcFyyFzXTy5whIP6BR8oedflSwKyS5TRD9a0U9zVk0cLzdE5nFfDbGehqVStZ7ra9pN-lGyljRl7YRF_qFt_d1lfWdr01OPLAlUB20qXb4xfB9jjhRHpgG3lIKY5yDw_d6KCZIJbKr9r4ewnKFU0Vx-NpSw3svjgvUtW1VXP4_7hy9_3lQ../download [following]\n",
            "--2019-02-25 19:48:10--  https://public.boxcloud.com/d/1/b1!7hNRhZtY_F5cz5W5wy_zfhHec_4QTG6WWnnNaIbW0bF1eoXpL8seHYNcC45FYf4P2HIQ6yrgZxK7BmIQ2DsC0Lab2iX1Hj12a8400wqR1Mr-9GPnySkkvDdnkhJAlyGM7W7dMoTrL94XStGK6E581vMw_0L95V_9qgFO7g3anzMVRZJHiYM7AUk4FfPtJmUQZoGHN372a6VNYNdpAQahvYgMijVjZb0lXXa40TL07Yqc-WcmQKlBaeeSCc9-oJxAlc8SKRDoYmZruQOD81kWRsgs4ypGT3CkxwBdh87NYAGBZSPCNLTvQikxFPTCBx8Vk6Dl_EcbhSZJHGgGrjwA0UL9UH_nTeB4tQnBp3MEfnIIMftjN7M_yoJ-yEExjkbZzfRcGZENpR6KBhsaZue_mXSUa29JUr5YT0N49gvC6lr7rJQsVP8-bdSAF5st9wn2ISd814bOjHr3n98bXvSBdSaYblvsXE3aFc4u9APFT3iei3MtgPgR-FjlxiB4ClL24LczPKrwbJrYAFYDl5siKBIeXn6eKYob9cBKYPoUUTnDt1wrZemgu0ColxEa836ZIsaTyU3rAnSUuSWF_APmEE3HUxrjhZbZjUkQcAsuDx6eYl4vR92WdB9kS66DVZrrgQ3Bpen6xA_6Oc_PkW1WgCJb3Sly0h1_0kjcguIUYiw-sMAIOPnLAnsXnAR1OCkXywZBlFzF9LEAJJ56VLcOVI0khnTfSo8DHk49t19l8HJvw4b6wwmC-wvDeH9HiMscm2a0zlc0Gkofrwxhap5qtLsl68DXMJBS5P6iIy7ffpSV91TKcvouo53dDofxYaIlddU6O0Bhatws7fQJfkD_6j0UVJ5NwlCwzn70Ch5Q13tsebtRtP0xL37Ijwci59KzvnL4nb55Y-yHTEpioBDmmDkyjwKJnn4MOFw9qhf8ZiEaVp-0i29V8NEX8fznFWhF-ihw3wf4X21GYGW9fqa0Qk52yOB0rEqRV6ncIU_nJCQZ2yEMGbNu00kpvRJ7JVkMZPb-rvi_lFUlbqWclBv3j8IzH2nztBDOB0fL1mc000nERJWOgihyAEqVah0lfxOlbJtrVkN45GVRUO0R2e1wjYg7H8tBlfFVyohWYxH8AE-KSNe9AlHt3IrO4fyuELm4kljve1q5qHHpQEpBQJAs072pr-O3FsGOOQwvqbBDFLvYlnB4W5rAGfwqmuL-KVvOGK4QkqzNJrfxmRwuFK4wXmilACUSuHMEiyFjRJniVHE3Ea3-YFYdTlPeuKHWx2r5QcFyyFzXTy5whIP6BR8oedflSwKyS5TRD9a0U9zVk0cLzdE5nFfDbGehqVStZ7ra9pN-lGyljRl7YRF_qFt_d1lfWdr01OPLAlUB20qXb4xfB9jjhRHpgG3lIKY5yDw_d6KCZIJbKr9r4ewnKFU0Vx-NpSw3svjgvUtW1VXP4_7hy9_3lQ../download\n",
            "Resolving public.boxcloud.com (public.boxcloud.com)... 107.152.26.200\n",
            "Connecting to public.boxcloud.com (public.boxcloud.com)|107.152.26.200|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4088106554 (3.8G) [application/zip]\n",
            "Saving to: ‘hpatches_data.zip’\n",
            "\n",
            "hpatches_data.zip   100%[===================>]   3.81G  21.0MB/s    in 3m 19s  \n",
            "\n",
            "2019-02-25 19:51:29 (19.6 MB/s) - ‘hpatches_data.zip’ saved [4088106554/4088106554]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FtXex_nAxNwq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Get Denoise Model (Add)"
      ]
    },
    {
      "metadata": {
        "id": "FD4URA2g5-u2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fe996183-b1c3-4d91-eea8-511f6a3a91fb"
      },
      "cell_type": "code",
      "source": [
        "from denoise_network import *\n",
        "from get_data import get_data\n",
        "\n",
        "EPOCHS = 50\n",
        "\n",
        "seqs_train, seqs_test = get_data()\n",
        "\n",
        "# get traning data\n",
        "if os.path.exists('data/denoise_data/denoise_generator.npy') and os.path.exists('data/denoise_data/denoise_generator_val.npy'):\n",
        "    denoise_generator     = np.load('data/denoise_data/denoise_generator.npy'    )\n",
        "    denoise_generator_val = np.load('data/denoise_data/denoise_generator_val.npy')\n",
        "\n",
        "else:\n",
        "    denoise_generator     = DenoiseHPatches(seqs_train, batch_size=500)\n",
        "    denoise_generator_val = DenoiseHPatches(seqs_test, batch_size=500)\n",
        "    #np.save('data/denoise_data/denoise_generator.npy'    , denoise_generator    )\n",
        "    #np.save('data/denoise_data/denoise_generator_val.npy', denoise_generator_val)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 76/76 [01:30<00:00,  1.31s/it]\n",
            "100%|██████████| 40/40 [00:56<00:00,  1.16s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "JaEJ4-DKxNwr",
        "colab_type": "code",
        "outputId": "00bde5da-03b0-4d46-a51c-0dd9137b060e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1867
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import sys\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "import keras\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda, Reshape\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Input, UpSampling2D, concatenate\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from read_data import HPatches, DataGeneratorDesc, hpatches_sequence_folder, DenoiseHPatches, tps\n",
        "from utils import generate_desc_csv, plot_denoise, plot_triplet\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#from common import *\n",
        "#from denoise_network import *\n",
        "#from get_data import get_data\n",
        "\n",
        "\n",
        "# denoise model\n",
        "def get_denoise_model(shape):\n",
        "\n",
        "  inputs = Input(shape)\n",
        "  conv1 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "                 #kernel_regularizer=regularizers.l2(0.0001),activity_regularizer=regularizers.l1(0.00001),\n",
        "\n",
        "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "  ## Bottleneck\n",
        "  conv2 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "                 #kernel_regularizer=regularizers.l2(0.0001), activity_regularizer=regularizers.l1(0.00001),\n",
        "\n",
        "\n",
        "  ## Now the decoder starts\n",
        "  up3 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv2))\n",
        "               #kernel_regularizer=regularizers.l2(0.0001), activity_regularizer=regularizers.l1(0.00001),\n",
        "\n",
        "  merge3 = concatenate([conv1,up3], axis = -1)\n",
        "  conv3 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge3)\n",
        "                 #kernel_regularizer=regularizers.l2(0.0001), activity_regularizer=regularizers.l1(0.00001),\n",
        "\n",
        "\n",
        "  conv4 = Conv2D(1, 3,  padding = 'same')(conv3)\n",
        "\n",
        "  shallow_unet = Model(inputs = inputs, outputs = conv4)\n",
        "  return shallow_unet\n",
        "\n",
        "def get_denoise_model_add(shape):\n",
        "\n",
        "  inputs = Input(shape)\n",
        "  conv1 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "                 #kernel_regularizer=regularizers.l2(0.0001),activity_regularizer=regularizers.l1(0.00001),\n",
        "\n",
        "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "  ## Bottleneck\n",
        "  conv2 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "                 #kernel_regularizer=regularizers.l2(0.0001), activity_regularizer=regularizers.l1(0.00001),\n",
        "\n",
        "\n",
        "  ## Now the decoder starts\n",
        "  up3 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv2))\n",
        "               #kernel_regularizer=regularizers.l2(0.0001), activity_regularizer=regularizers.l1(0.00001),\n",
        "\n",
        "  merge3 = Add([conv1,up3], axis = -1)\n",
        "  conv3 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge3)\n",
        "                 #kernel_regularizer=regularizers.l2(0.0001), activity_regularizer=regularizers.l1(0.00001),\n",
        "\n",
        "\n",
        "  conv4 = Conv2D(1, 3,  padding = 'same')(conv3)\n",
        "\n",
        "  shallow_unet = Model(inputs = inputs, outputs = conv4)\n",
        "  return shallow_unet\n",
        "\n",
        "\n",
        "# get model\n",
        "shape = (32, 32, 1)\n",
        "denoise_model = get_denoise_model(shape)\n",
        "\n",
        "# callbacks\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 5, verbose = 3, mode= 'auto'),\n",
        "    keras.callbacks.ModelCheckpoint('data/denoise_model.weights.{epoch:02d}-{val_loss:.2f}.hdf5', verbose=1, save_best_only=True)\n",
        "]\n",
        "\n",
        "# optimiser\n",
        "opt  = opt = keras.optimizers.nadam()\n",
        "\n",
        "# loss\n",
        "loss = 'mean_absolute_error'\n",
        "\n",
        "# train network\n",
        "denoise_model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
        "denoise_history = denoise_model.fit_generator(generator=denoise_generator, epochs=EPOCHS, callbacks=callbacks,\n",
        "                                              verbose=1, validation_data=denoise_generator_val)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDNN_VERSION=7.4.2.24\n",
            "_=/usr/bin/printenv\n",
            "LANG=en_US.UTF-8\n",
            "HOSTNAME=42e360808994\n",
            "XRT_TPU_CONFIG=tpu_worker;0;10.101.254.34:8470\n",
            "OLDPWD=/\n",
            "CLOUDSDK_CONFIG=/content/.config\n",
            "NVIDIA_VISIBLE_DEVICES=all\n",
            "DATALAB_SETTINGS_OVERRIDES={\"kernelManagerProxyPort\":6000,\"kernelManagerProxyHost\":\"172.28.0.3\",\"jupyterArgs\":[\"--ip=\\\"172.28.0.2\\\"\"]}\n",
            "ENV=/root/.bashrc\n",
            "PAGER=cat\n",
            "NCCL_VERSION=2.4.2\n",
            "TF_FORCE_GPU_ALLOW_GROWTH=true\n",
            "JPY_PARENT_PID=41\n",
            "NO_GCE_CHECK=True\n",
            "PWD=/content/deepLearning\n",
            "HOME=/root\n",
            "CLICOLOR=1\n",
            "DEBIAN_FRONTEND=noninteractive\n",
            "COLAB_USE_SEABORN_STYLE=1\n",
            "LIBRARY_PATH=/usr/local/cuda/lib64/stubs\n",
            "GLIBCPP_FORCE_NEW=1\n",
            "TERM=xterm-color\n",
            "SHELL=/bin/bash\n",
            "GCS_READ_CACHE_BLOCK_SIZE_MB=16\n",
            "PYTHONWARNINGS=ignore:::pip._internal.cli.base_command\n",
            "MPLBACKEND=module://ipykernel.pylab.backend_inline\n",
            "CUDA_PKG_VERSION=10-0=10.0.130-1\n",
            "CUDA_VERSION=10.0.130\n",
            "NVIDIA_DRIVER_CAPABILITIES=compute,utility\n",
            "COLAB_TPU_ADDR=10.101.254.34:8470\n",
            "SHLVL=2\n",
            "PYTHONPATH=/env/python\n",
            "NVIDIA_REQUIRE_CUDA=cuda>=10.0 brand=tesla,driver>=384,driver<385\n",
            "COLAB_GPU=0\n",
            "GLIBCXX_FORCE_NEW=1\n",
            "PATH=/usr/local/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin\n",
            "LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4\n",
            "TPU_NAME=grpc://10.101.254.34:8470\n",
            "GIT_PAGER=cat\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/50\n",
            "   4/3117 [..............................] - ETA: 6:39:51 - loss: 438.1477 - acc: 0.0019"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-e46906700321>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0mdenoise_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m denoise_history = denoise_model.fit_generator(generator=denoise_generator, epochs=EPOCHS, callbacks=callbacks,\n\u001b[0;32m--> 100\u001b[0;31m                                               verbose=1, validation_data=denoise_generator_val)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "lWednqpdxNwv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}